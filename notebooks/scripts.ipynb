{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import boto3\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from io import BytesIO\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'AcousticSounds'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mAcousticSounds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AcousticSoundsData\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CNNNetwork\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'AcousticSounds'"
     ]
    }
   ],
   "source": [
    "from AcousticSounds import AcousticSoundsData\n",
    "from cnn import CNNNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_datasets():\n",
    "    train_data = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    validation_data = datasets.MNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "    return train_data, validation_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# download data and create data loader\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     train_data, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_mnist_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset Downloaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mdownload_mnist_datasets\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_mnist_datasets\u001b[39m():\n\u001b[1;32m----> 2\u001b[0m     train_data \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241m.\u001b[39mMNIST(\n\u001b[0;32m      3\u001b[0m         root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m         train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m         download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m         transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     validation_data \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMNIST(\n\u001b[0;32m      9\u001b[0m         root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m         train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m         download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m         transform\u001b[38;5;241m=\u001b[39mToTensor(),\n\u001b[0;32m     13\u001b[0m     )\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data, validation_data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # download data and create data loader\n",
    "    train_data, _ = download_mnist_datasets()\n",
    "    print(\"Dataset Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "There are 10 samples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AcousticSoundsData(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 annotations_file,\n",
    "                 #audio_dir,\n",
    "                 transformation,\n",
    "                 target_sample_rate,\n",
    "                 num_samples,\n",
    "                 device,\n",
    "                 bucket_name\n",
    "                 ):\n",
    "        self.annotations = pd.read_excel(annotations_file)\n",
    "        #self.audio_dir = audio_dir\n",
    "        self.device = device\n",
    "        self.transformation = transformation.to(self.device)\n",
    "        self.target_sample_rate = target_sample_rate\n",
    "        self.num_samples = num_samples\n",
    "        self.bucket_name = bucket_name\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index, self.bucket_name)\n",
    "        label = self._get_audio_sample_label(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = signal.to(self.device)\n",
    "        signal = self._resample_if_necessary(signal, sr)\n",
    "        signal = self._mix_down_if_necessary(signal)\n",
    "        signal = self._cut_if_necessary(signal)\n",
    "        signal = self._right_pad_if_necessary(signal)\n",
    "        signal = self.transformation(signal)\n",
    "        return signal, label\n",
    "\n",
    "    def _cut_if_necessary(self, signal):\n",
    "        if signal.shape[1] > self.num_samples:\n",
    "            signal = signal[:, :self.num_samples]\n",
    "        return signal\n",
    "\n",
    "    def _right_pad_if_necessary(self, signal):\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < self.num_samples:\n",
    "            num_missing_samples = self.num_samples - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        return signal\n",
    "\n",
    "    def _resample_if_necessary(self, signal, sr):\n",
    "        if sr != self.target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _mix_down_if_necessary(self, signal):\n",
    "        if signal.shape[0] > 1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index, bucket_name):\n",
    "        path = self.annotations.iloc[index, 10]\n",
    "        s3 = boto3.client('s3')\n",
    "        audio_data = io.BytesIO()\n",
    "        s3.download_fileobj(bucket_name, path, audio_data)\n",
    "        audio_data.seek(0)\n",
    "        return audio_data\n",
    "\n",
    "    def _get_audio_sample_label(self, index):\n",
    "        return self.annotations.iloc[index, 6]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    BUCKET = '2307-01-acoustic-loggers-for-leak-detection-a'\n",
    "    object_key = 'Metadata_Audio_Connected/train_data.xlsx'\n",
    "\n",
    "    response = s3.get_object(Bucket=BUCKET, Key=object_key)\n",
    "    excel_data = response['Body'].read()\n",
    "\n",
    "    s3_location = BytesIO(excel_data)\n",
    "    \n",
    "    ANNOTATIONS_FILE = s3_location\n",
    "    #AUDIO_DIR = \"/home/valerio/datasets/UrbanSound8K/audio\"\n",
    "    SAMPLE_RATE = 22050\n",
    "    NUM_SAMPLES = 22050\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using device {device}\")\n",
    "\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "    usd = AcousticSoundsData(ANNOTATIONS_FILE,\n",
    "                            #AUDIO_DIR,\n",
    "                        mel_spectrogram,\n",
    "                        SAMPLE_RATE,\n",
    "                        NUM_SAMPLES,\n",
    "                        device,\n",
    "                        BUCKET)\n",
    "    print(f\"There are {len(usd)} samples in the dataset.\")\n",
    "    signal, label = usd[0]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 66, 46]             160\n",
      "              ReLU-2           [-1, 16, 66, 46]               0\n",
      "         MaxPool2d-3           [-1, 16, 33, 23]               0\n",
      "            Conv2d-4           [-1, 32, 35, 25]           4,640\n",
      "              ReLU-5           [-1, 32, 35, 25]               0\n",
      "         MaxPool2d-6           [-1, 32, 17, 12]               0\n",
      "            Conv2d-7           [-1, 64, 19, 14]          18,496\n",
      "              ReLU-8           [-1, 64, 19, 14]               0\n",
      "         MaxPool2d-9             [-1, 64, 9, 7]               0\n",
      "           Conv2d-10           [-1, 128, 11, 9]          73,856\n",
      "             ReLU-11           [-1, 128, 11, 9]               0\n",
      "        MaxPool2d-12            [-1, 128, 5, 4]               0\n",
      "          Flatten-13                 [-1, 2560]               0\n",
      "           Linear-14                   [-1, 10]          25,610\n",
      "          Softmax-15                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 122,762\n",
      "Trainable params: 122,762\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.83\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 2.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class CNNNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / linear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(128 * 5 * 4, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "        predictions = self.softmax(logits)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cnn = CNNNetwork()\n",
    "    summary(cnn.cpu(), (1, 64, 44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n",
      "CNNNetwork(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=2560, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s3 = boto3.client('s3')\n",
    "BUCKET = '2307-01-acoustic-loggers-for-leak-detection-a'\n",
    "object_key = 'Metadata_Audio_Connected/Connected_data.xlsx'\n",
    "\n",
    "response = s3.get_object(Bucket=BUCKET, Key=object_key)\n",
    "excel_data = response['Body'].read()\n",
    "\n",
    "s3_location = BytesIO(excel_data)\n",
    "    \n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "ANNOTATIONS_FILE = s3_location\n",
    "#AUDIO_DIR = \"/home/valerio/datasets/UrbanSound8K/audio\"\n",
    "SAMPLE_RATE = 22050\n",
    "NUM_SAMPLES = 22050\n",
    "\n",
    "\n",
    "def create_data_loader(train_data, batch_size):\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "    return train_dataloader\n",
    "\n",
    "\n",
    "def train_single_epoch(model, data_loader, loss_fn, optimiser, device):\n",
    "    for input, target in data_loader:\n",
    "        input, target = input.to(device), target.to(device)\n",
    "\n",
    "        # calculate loss\n",
    "        prediction = model(input)\n",
    "        loss = loss_fn(prediction, target)\n",
    "\n",
    "        # backpropagate error and update weights\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "    print(f\"loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def train(model, data_loader, loss_fn, optimiser, device, epochs):\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\")\n",
    "        train_single_epoch(model, data_loader, loss_fn, optimiser, device)\n",
    "        print(\"---------------------------\")\n",
    "    print(\"Finished training\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "    print(f\"Using {device}\")\n",
    "\n",
    "    # instantiating our dataset object and create data loader\n",
    "    mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=1024,\n",
    "        hop_length=512,\n",
    "        n_mels=64\n",
    "    )\n",
    "\n",
    "    usd = AcousticSoundsData(ANNOTATIONS_FILE,\n",
    "                            #AUDIO_DIR,\n",
    "                            mel_spectrogram,\n",
    "                            SAMPLE_RATE,\n",
    "                            NUM_SAMPLES,\n",
    "                            device,\n",
    "                            BUCKET\n",
    "                            )\n",
    "    \n",
    "    train_dataloader = create_data_loader(usd, BATCH_SIZE)\n",
    "\n",
    "    # construct model and assign it to device\n",
    "    cnn = CNNNetwork().to(device)\n",
    "    print(cnn)\n",
    "\n",
    "    # initialise loss funtion + optimiser\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.Adam(cnn.parameters(),\n",
    "                                 lr=LEARNING_RATE)\n",
    "\n",
    "    # train model\n",
    "    train(cnn, train_dataloader, loss_fn, optimiser, device, EPOCHS)\n",
    "\n",
    "    # save model\n",
    "    torch.save(cnn.state_dict(), \"feedforwardnet.pth\")\n",
    "    print(\"Trained feed forward net saved at feedforwardnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.34.83)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.83 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3) (1.34.83)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.35.0,>=1.34.83->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from botocore<1.35.0,>=1.34.83->boto3) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.83->boto3) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\percy\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.0.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lazy-loader>=0.1->librosa) (23.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\percy\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.0->librosa) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.0->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\percy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'folder_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m audio_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 35\u001b[0m response \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39mlist_objects_v2(Bucket\u001b[38;5;241m=\u001b[39mbucket_name, Prefix\u001b[38;5;241m=\u001b[39m\u001b[43mfolder_name\u001b[49m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContents\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     37\u001b[0m     audio_file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folder_name' is not defined"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install boto3\n",
    "!pip install librosa\n",
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "\n",
    "# Import libraries\n",
    "import boto3\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Set AWS credentials directly in the code\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'AKIATNJHRXAPQBHVQARV'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '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'\n",
    "\n",
    "# Specify the bucket name and folder name\n",
    "bucket_name = '2307-01-acoustic-loggers-for-leak-detection-a'\n",
    "file_name = 'train_data.xlsx'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Function to load audio data from S3\n",
    "def load_audio_data_from_s3(bucket, key):\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    audio_data = obj['Body'].read()\n",
    "    return audio_data\n",
    "\n",
    "# Load audio data and labels from S3\n",
    "audio_data = []\n",
    "labels = []\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_name)\n",
    "for file in response['Contents']:\n",
    "    audio_file = file['Key']\n",
    "    audio_bytes = load_audio_data_from_s3(bucket_name, audio_file)\n",
    "    audio, sr = librosa.load(io.BytesIO(audio_bytes), sr=None)\n",
    "    audio_data.append(audio)\n",
    "    labels.append(file['Label'])  # Assuming labels are stored in S3\n",
    "\n",
    "# Convert audio data and labels to numpy arrays\n",
    "audio_data = np.array(audio_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv1D(64, 3, activation='relu', input_shape=(None, 1)),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Conv1D(128, 3, activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(audio_data, labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('audio_classification_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
